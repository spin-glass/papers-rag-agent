"""Message routing workflow using LangGraph."""

from typing import TypedDict, Optional, Literal, Any
from langgraph.graph import StateGraph, START, END
from langchain_core.runnables import RunnableConfig

from src.models import EnhancedAnswerResult
from src.graphs.corrective_rag import answer_with_correction_graph
from src.retrieval.arxiv_searcher import run_arxiv_search
from src.config import get_graph_recursion_limit


class MessageState(TypedDict):
    """State for message routing workflow."""

    message_content: str
    message_type: str
    rag_index: Optional[Any]
    arxiv_results: Optional[list]
    rag_result: Optional[EnhancedAnswerResult]
    final_response: Optional[str]
    error: Optional[str]


def classify_message_node(state: MessageState) -> MessageState:
    """Classify the incoming message type."""
    try:
        message = state["message_content"].strip().lower()

        print(f"ğŸ“ Classifying message: {message[:50]}...")

        # Check for explicit arxiv search command ONLY
        if message.startswith("arxiv:"):
            state["message_type"] = "arxiv"
            print("âœ… Classified as: ArXiv search")
        else:
            # All other messages are treated as RAG questions
            state["message_type"] = "rag"
            print("âœ… Classified as: RAG question")

    except Exception as e:
        print(f"âŒ Message classification failed: {e}")
        state["message_type"] = "rag"  # Default to RAG
        state["error"] = f"Classification error: {str(e)}"

    return state


def arxiv_search_node(state: MessageState) -> MessageState:
    """Handle ArXiv search requests."""
    try:
        message = state["message_content"]

        # Extract search query
        if message.lower().startswith("arxiv:"):
            query = message.split(":", 1)[1].strip()
        else:
            # For paper search questions, extract the research topic
            query = extract_research_topic(message)

        print(f"ğŸ” Searching ArXiv for: {query}")

        # Perform ArXiv search
        results = run_arxiv_search(query, max_results=5)
        state["arxiv_results"] = results

        print(f"âœ… ArXiv search completed: {len(results)} results")

    except Exception as e:
        print(f"âŒ ArXiv search failed: {e}")
        state["arxiv_results"] = []
        state["error"] = f"ArXiv search error: {str(e)}"

    return state


def extract_research_topic(message: str) -> str:
    """Extract research topic from natural language paper search query."""
    message_lower = message.lower()

    # Common patterns for extracting research topics
    if "transformer" in message_lower:
        return "transformer"
    elif "æ©Ÿæ¢°å­¦ç¿’" in message_lower or "machine learning" in message_lower:
        return "machine learning"
    elif "æ·±å±¤å­¦ç¿’" in message_lower or "deep learning" in message_lower:
        return "deep learning"
    elif "è‡ªç„¶è¨€èªå‡¦ç†" in message_lower or "nlp" in message_lower:
        return "natural language processing"
    elif "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³" in message_lower or "computer vision" in message_lower:
        return "computer vision"
    elif "å¼·åŒ–å­¦ç¿’" in message_lower or "reinforcement learning" in message_lower:
        return "reinforcement learning"
    else:
        # Default: extract key nouns or use the whole message
        return (
            message.replace("æœ€è¿‘ã®", "")
            .replace("è«–æ–‡ã‚’æ¢ã—ã¦ã„ã¾ã™", "")
            .replace("ã«ã¤ã„ã¦", "")
            .strip()
        )


def rag_pipeline_node(state: MessageState) -> MessageState:
    """Handle RAG questions with enhanced content generation."""
    try:
        question = state["message_content"]
        index = state["rag_index"]

        print(f"ğŸ¤– Processing RAG question: {question[:50]}...")

        # Check if index is available
        if not index:
            state["error"] = "RAG index not available"
            return state

        # Run corrective RAG workflow
        basic_result = answer_with_correction_graph(question, index=index)

        # Re-enable content enhancement with Cornell Note and Quiz
        try:
            from src.graphs.content_enhancement import enhance_answer_content

            enhanced_result = enhance_answer_content(basic_result, question)
            # Ensure metadata is preserved
            if not enhanced_result.metadata and basic_result.metadata:
                enhanced_result.metadata = basic_result.metadata
        except Exception as e:
            print(f"âš ï¸ Content enhancement failed, using basic result: {e}")
            # Fallback to simple enhanced result
            from src.models import EnhancedAnswerResult

            enhanced_result = EnhancedAnswerResult(
                text=basic_result.text,
                citations=basic_result.citations,
                support=basic_result.support,
                attempts=basic_result.attempts,
                cornell_note=None,
                quiz_items=[],
                metadata=basic_result.metadata,  # Pass through support details
            )

        state["rag_result"] = enhanced_result

        print(f"âœ… RAG processing completed. Support: {enhanced_result.support:.3f}")

    except Exception as e:
        print(f"âŒ RAG pipeline failed: {e}")
        state["error"] = f"RAG pipeline error: {str(e)}"

    return state


def format_arxiv_response_node(state: MessageState) -> MessageState:
    """Format ArXiv search results for display."""
    try:
        results = state.get("arxiv_results", [])

        if not results:
            state["final_response"] = "è©²å½“ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            return state

        # Format results
        lines = []
        for result in results:
            if result.get("pdf"):
                lines.append(
                    f"- [{result['title']}]({result['link']})  â€¢  [PDF]({result['pdf']})"
                )
            else:
                lines.append(f"- [{result['title']}]({result['link']})")

        response = "### ArXivæ¤œç´¢çµæœ\n" + "\n".join(lines)
        state["final_response"] = response

        print(f"âœ… ArXiv response formatted: {len(results)} results")

    except Exception as e:
        print(f"âŒ ArXiv response formatting failed: {e}")
        state["final_response"] = "æ¤œç´¢çµæœã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        state["error"] = f"ArXiv formatting error: {str(e)}"

    return state


def format_rag_response_node(state: MessageState) -> MessageState:
    """Format RAG results for display."""
    try:
        result = state.get("rag_result")

        if not result:
            state["final_response"] = "å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            return state

        # Build response content
        response_parts = []

        # Main answer
        response_parts.append(f"## å›ç­”\n\n{result.text}")

        # Citations
        if result.citations:
            response_parts.append("\n## å¼•ç”¨æ–‡çŒ®\n")
            for i, citation in enumerate(result.citations, 1):
                response_parts.append(f"{i}. [{citation['title']}]({citation['link']})")

        # Cornell Note
        if result.cornell_note:
            response_parts.append(
                f"\n## Cornell Note\n\n### Cue\n\n{result.cornell_note.cue}"
            )
            response_parts.append(f"\n### Notes\n\n{result.cornell_note.notes}")
            response_parts.append(f"\n### Summary\n\n{result.cornell_note.summary}")

        # Quiz
        if result.quiz_items:
            response_parts.append("\n## ç†è§£åº¦ãƒã‚§ãƒƒã‚¯\n")
            for i, quiz in enumerate(result.quiz_items, 1):
                response_parts.append(f"\n### å•é¡Œ {i}\n\n{quiz.question}\n")
                for option in quiz.options:
                    marker = "âœ“ " if option.id == quiz.correct_answer else ""
                    response_parts.append(
                        f"- {marker}{option.id.upper()}: {option.text}"
                    )

        # Support score with detailed information
        support_level = _format_support_level(result.support)
        response_parts.append("\n## æ¤œç´¢å“è³ªæƒ…å ±")

        # Check if we have metadata with support details
        if result.metadata and result.metadata.get("baseline_support") is not None:
            baseline_support = result.metadata["baseline_support"]
            enhanced_support = result.metadata.get("enhanced_support")
            threshold = result.metadata["threshold"]
            threshold_met = result.metadata["threshold_met"]

            response_parts.append(f"**åŸºæœ¬æ¤œç´¢Support: {baseline_support:.3f}**")
            if enhanced_support is not None:
                response_parts.append(f"**HyDEæ‹¡å¼µå¾ŒSupport: {enhanced_support:.3f}**")
            response_parts.append(f"**é–¾å€¤: {threshold:.3f}**")
            response_parts.append(
                f"**æœ€çµ‚Support: {result.support:.3f} ({support_level})**"
            )

            if not threshold_met and result.support == 0.0:
                response_parts.append(
                    "âš ï¸ **Supportå€¤ãŒé–¾å€¤ã‚’ä¸‹å›ã£ãŸãŸã‚ã€no-answerå¿œç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ**"
                )
            elif threshold_met:
                response_parts.append(
                    "âœ… **é–¾å€¤ã‚’æº€ãŸã—ã¦ã„ã‚‹ãŸã‚ã€å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ**"
                )
        else:
            response_parts.append(
                f"**Support: {support_level} (score={result.support:.3f})**"
            )

        # HyDE usage info
        if len(result.attempts) > 1:
            response_parts.append("\n*HyDEè£œæ­£æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ*")

        state["final_response"] = "\n".join(response_parts)

        print("âœ… RAG response formatted successfully")

    except Exception as e:
        print(f"âŒ RAG response formatting failed: {e}")
        state["final_response"] = f"å›ç­”ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        state["error"] = f"RAG formatting error: {str(e)}"

    return state


def _format_support_level(support_score: float) -> str:
    """Format support score as High/Med/Low."""
    if support_score >= 0.8:
        return "High"
    elif support_score >= 0.62:
        return "Med"
    else:
        return "Low"


def route_message_type(state: MessageState) -> Literal["arxiv", "rag"]:
    """Route message based on classified type."""
    return state["message_type"]


def route_to_formatter(state: MessageState) -> Literal["format_arxiv", "format_rag"]:
    """Route to appropriate formatter based on message type."""
    return "format_arxiv" if state["message_type"] == "arxiv" else "format_rag"


def create_message_routing_graph() -> StateGraph:
    """Create the message routing workflow graph."""

    # Define the graph
    graph = StateGraph(MessageState)

    # Add nodes
    graph.add_node("classify", classify_message_node)
    graph.add_node("arxiv_search", arxiv_search_node)
    graph.add_node("rag_pipeline", rag_pipeline_node)
    graph.add_node("format_arxiv", format_arxiv_response_node)
    graph.add_node("format_rag", format_rag_response_node)

    # Define the flow
    graph.add_edge(START, "classify")

    # Route based on message type
    graph.add_conditional_edges(
        "classify", route_message_type, {"arxiv": "arxiv_search", "rag": "rag_pipeline"}
    )

    # Route to appropriate formatter
    graph.add_edge("arxiv_search", "format_arxiv")
    graph.add_edge("rag_pipeline", "format_rag")

    graph.add_edge("format_arxiv", END)
    graph.add_edge("format_rag", END)

    return graph.compile()


def process_message_with_routing(message_content: str, rag_index: Any = None) -> str:
    """
    Process incoming message using LangGraph routing workflow.

    Args:
        message_content: User message content
        rag_index: RAG index for retrieval (required for RAG questions)

    Returns:
        Formatted response string
    """
    try:
        # Create the message routing graph
        routing_graph = create_message_routing_graph()

        # Prepare initial state
        initial_state = MessageState(
            message_content=message_content,
            message_type="",
            rag_index=rag_index,
            arxiv_results=None,
            rag_result=None,
            final_response=None,
            error=None,
        )

        print("ğŸš€ Starting message routing workflow...")

        # Create RunnableConfig with recursion limit
        config = RunnableConfig(recursion_limit=get_graph_recursion_limit())

        # Run the routing workflow
        final_state = routing_graph.invoke(initial_state, config=config)

        # Check for errors
        if final_state.get("error"):
            print(f"âš ï¸ Workflow completed with errors: {final_state['error']}")

        # Return the final response
        response = final_state.get("final_response")
        if response:
            print("âœ… Message routing completed successfully")
            return response
        else:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

    except Exception as e:
        print(f"âŒ Message routing workflow failed: {e}")
        return f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
